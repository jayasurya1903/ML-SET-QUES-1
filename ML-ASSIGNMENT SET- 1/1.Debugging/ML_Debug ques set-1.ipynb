{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "163c380c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature1  Feature2\n",
      "0        10       5.5\n",
      "1        20       6.7\n",
      "2        30       8.9\n"
     ]
    }
   ],
   "source": [
    "#1.Debug the given code\n",
    "import pandas as pd\n",
    "\n",
    "data = {'Feature1': ['10', '20', '30'],  # 'Thirty' is not a valid number\n",
    "        'Feature2': [5.5, 6.7, 8.9]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['Feature1'] = df['Feature1'].astype(int)  # Error: Cannot convert 'Thirty' to int\n",
    "\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75ed407d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B\n",
      "0  1.0  4.0\n",
      "1  2.0  5.0\n",
      "2  1.5  6.0\n"
     ]
    }
   ],
   "source": [
    "#2.\n",
    "import pandas as pd\n",
    "\n",
    "data = {'A': [1, 2, None],  # Missing value\n",
    "        'B': [4, None, 6]}  # Missing value\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "mean_value = df.mean()\n",
    "num=df.fillna(mean_value)  # Error: fillna() does not modify in place\n",
    "\n",
    "print(num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e65cb6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = np.array([[1], [2], [3], [4], [5]])  # Error: X should be 2D\n",
    "y = np.array([2, 4, 6, 8, 10])\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b60f10de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.41421356]\n",
      " [-0.70710678]\n",
      " [ 0.        ]\n",
      " [ 0.70710678]\n",
      " [ 1.41421356]]\n"
     ]
    }
   ],
   "source": [
    "#4.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "data = np.array([[10], [20], [30], [40], [50]])  # Error: Should be 2D\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "print(scaled_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da46280a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayas\\anaconda3\\envs\\aiml\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "X = [[1, 2], [3, 4], [5, 6]]\n",
    "y = ['yes', 'no', 'yes']  # Error: Labels should be numeric\n",
    "lb=LabelEncoder()\n",
    "lb=lb.fit_transform(y)\n",
    "model = LogisticRegression()\n",
    "model.fit(X, lb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6845ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#6.import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df = pd.DataFrame({'Category': ['A', 'B', 'C', 'A']})\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False) \n",
    "encoded = encoder.fit_transform(df['Category'].values.reshape(-1, 1))  # Error: Data should be reshaped\n",
    "print(encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4e1665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8]]\n",
    "y = [0, 1, 0,1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f9a8ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayas\\anaconda3\\envs\\aiml\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7.from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "X_train = [[1, 2], [3, 4], [5, 6]]\n",
    "y_train = [\"yes\", \"no\", \"yes\"]  # Error: LogisticRegression expects numerical labels\n",
    "Y_train=LabelEncoder()\n",
    "Y_train=Y_train.fit_transform(y_train)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee13984b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "# Creating a dataset with missing values\n",
    "X_train = np.array([[1, 2], [3, np.nan], [5, 6]])\n",
    "y_train = np.array([10, 20, 30])\n",
    "X= SimpleImputer(strategy='mean')\n",
    "x_train= X.fit_transform(X_train)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29fdd8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#9.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train = [[1, 2], [3, 4], [5, 6]]\n",
    "y_train = [\"spam\", \"ham\", \"spam\"]  # Error: String labels not allowed\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4057ff6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayas\\anaconda3\\envs\\aiml\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#10.\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train = [[1, 100], [2, 200], [3, 300]]\n",
    "y_train = [0, 1, 0]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.predict([[1, 150]]))  # Unreliable output due to large-scale difference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c1234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
